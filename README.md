# Overview

This document is for describing the data flow of SmoothTV

## Step 1. Sending events from the Scoreboard app

### Match Start event
```js
const matchStartEvent: MatchEvent = {
  timestamp: new Date(),
  matchId: 1,
  inGameTime: 0,
  type: MatchEventType.MATCH_START,
};
```

### Point event
```js
const pointEvent: PointEvent = {
  timestamp: new Date(),
  matchId: 1,
  playerId: 1,
  inGameTime: 10,
  type: PointEventType.POINT,
  value: 3,
};
```

## Step 2. Backend writing event to Firestore or Firebase

Both options here are valid, it comes to down to cost and we want to be able to do with the data while it is "live".
LetÂ´s do some calculations, lets say we have 10 MatchEvents and 10 PointEvents per match, that would result in about 0,5kb / match in a Firebase database and 20 writes in a Firestore database.
Lets say we 1 tournament is 500 matches.

### Firebase
0,5kb x 500 matches = 250kb storage
If 50 tournaments in a weekend = 12 Mb / weekend

The free tier in Firebase is 1GB free storage, and 10GB download per month.
After that its $5/GB storage, and $1 per downloaded GB.
So we could basically run the entire platform on the free tier.


### Firestore
20 writes x 500 matches = 10 000 writes
if 50 tournaments in a weekend = 500 000 writes (250 000 writes/day)

This is the current pricing for Firestore

![image](https://github.com/ralcar/smoothtv-docs/assets/10072001/25758921-38fa-4e7e-a369-b522f2fcba32)

![image](https://github.com/ralcar/smoothtv-docs/assets/10072001/5144f653-6a8e-45e4-8500-1fefc5b18dce)

500 000 writes every weekend = 2 million every month.
Based on their pricing, that would be $4.50 / month for writing.

For reading, lets say we have 200 tournaments every month.
If every tournament has 100 viewers, and each viewer watches 30 matches.

### 100 viewers / tournament ($4 / month)
```
Total writes for 200 tournaments: 2,000,000 writes.
Total reads generated by the viewers for 200 tournaments: 12,000,000 reads.
Daily billable reads: 350,000 reads (averaged over a month), as the daily average reads amount to 400,000 (12,000,000 divided by 30 days), which exceeds the daily free quota of 50,000.
Total monthly billable reads: 10,500,000 reads (350,000 daily billable reads x 30 days).
Monthly cost for reads: $4.095 (calculated based on the unit price of $0.039 per 100,000 reads).
Therefore, with 200 tournaments happening in a month, you would incur a cost of approximately $4.095 for reads.
```

### 1000 viewers / tournament ($46 / month)

```
Total reads generated by the viewers for one tournament: 600,000 reads (1000 viewers x 30 matches/viewer x 20 writes/match).
Total reads generated by the viewers for 200 tournaments: 120,000,000 reads (200 tournaments x 600,000 reads/tournament).
Daily billable reads: 3,950,000 reads (averaged over a month), as the daily average reads amount to 4,000,000 (120,000,000 divided by 30 days), which exceeds the daily free quota of 50,000.
Total monthly billable reads: 118,500,000 reads (3,950,000 daily billable reads x 30 days).
Monthly cost for reads: $46.215 (calculated based on the unit price of $0.039 per 100,000 reads).
Therefore, with 200 tournaments happening in a month and 1000 viewers per tournament, you would incur a cost of approximately $46.215 for reads.
```

## Step 3. Exporting finished matches to BigQuery

Every match that is finished, does not need to exist in Firebase/Firestore anymore. It should be moved to something like BigQuery, since that data will not change (unless error has occured ofcourse).
Moving data to BigQuery would drastically change the costs, and basically remove most of the Firebase/Firestore costs if we are good at transfering the data.
BigQuery costs can be found here: https://cloud.google.com/bigquery/pricing

## Step 4. Cleanup

When a tournament is over, we should have a integrity check, validate that all data has been moved to BigQuery.
After that it, if everything looks ok, it should be ok to remove the tournament from Firebase/Firestore in order to keep costs down.

# Highlight creation (Cloud functions)

Every time a record is written to Firebase/Firestore, we can evaluate the event and figure out if this should be a highlight.

Types of highlights that we can create for example, until we have solved how we will classify each event (converting it from a takedown => "double leg takedown")
```
SUBMISSION = match ended with submission
UNEXPECTED_SUBMISSION = match ended with a submission for the competitor that was clearly loosing
EARLY_SUBMISSION = quick submission
COMBO = multiple points within a short time period
DISQUALIFIQUATION = always fun to watch
```
If any of these events are detected, we could
- fetch video manifest
- figure out a start and stop time
- generate a highlight manifest
- store manifest on s3 for example, or base64 it into the database
- publish highlight to Firebase/Firestore, so that it can trigger the UI and notifications

## Extra credit = build caching layer on top of BigQuery

BigQuery is good at caching similar requests within a period of time, but as soon as you have some variable in the query or other factors, it will generate a query which results in a cost.
If we ever feel that we are doing unnecessarly many similar queries to BigQuery that should be the same, we can always create a caching layer on top that we can apply our own logic to.
